{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embeddings-computation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmKKbVYgRTQ2"
      },
      "source": [
        "Precomputing embeddings of the training dataset to accelerate the submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5LGsDROPpJl"
      },
      "source": [
        "import operator\n",
        "import gc\n",
        "import pathlib\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from scipy import spatial\n",
        "import cv2\n",
        "import math\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "from functools import partial"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbRreIoSP8MT"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "GCS_PATH = \"gs://landmark-recognition-2020\"\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = [736, 736]\n",
        "NUM_TO_RERANK = 1\n",
        "NUM_PUBLIC_TEST_IMAGES = 10345\n",
        "NUM_TRAIN_IMAGES = 1580470\n",
        "NUMBER_OF_CLASSES = 81313\n",
        "NUM_EMBEDDING_DIMENSIONS = 512\n",
        "DATASET_DIR = '/content/drive/MyDrive/kaggle/google-landmark-recognition-2021/train.csv'\n",
        "TEST_IMAGE_DIR = '/content/test'\n",
        "TRAIN_IMAGE_DIR = '../input/landmark-recognition-2021/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izVvTcWsP-2U"
      },
      "source": [
        "def decode_image(image):\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
        "    return image\n",
        "\n",
        "def read_tfrecord(example, labeled):\n",
        "    tfrecord_format = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"image_id\": tf.io.FixedLenFeature([], tf.string),\n",
        "        'landmark_id': tf.io.FixedLenFeature([], tf.int64)\n",
        "    } if labeled else {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"image_id\": tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = decode_image(example['image'])\n",
        "    if labeled:\n",
        "        label = tf.cast(example['landmark_id'], tf.int32)\n",
        "        label = tf.one_hot(label, N_CATEGORIES)\n",
        "        return image, label\n",
        "    idnum = example['image_id']\n",
        "    return image, idnum\n",
        "\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def get_dataset(filepaths, labeled=True, ordered=False):\n",
        "    dataset = load_dataset(filepaths, labeled=labeled, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTOTUNE)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdAxGye9QEJq"
      },
      "source": [
        "class ArcMarginProduct(tf.keras.layers.Layer):\n",
        "    '''\n",
        "    Implements large margin arc distance.\n",
        "\n",
        "    Reference:\n",
        "        https://arxiv.org/pdf/1801.07698.pdf\n",
        "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
        "            blob/master/src/modeling/metric_learning.py\n",
        "    '''\n",
        "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
        "                 ls_eps=0.0, **kwargs):\n",
        "\n",
        "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.ls_eps = ls_eps\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = tf.math.cos(m)\n",
        "        self.sin_m = tf.math.sin(m)\n",
        "        self.th = tf.math.cos(math.pi - m)\n",
        "        self.mm = tf.math.sin(math.pi - m) * m\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'n_classes': self.n_classes,\n",
        "            's': self.s,\n",
        "            'm': self.m,\n",
        "            'ls_eps': self.ls_eps,\n",
        "            'easy_margin': self.easy_margin,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(ArcMarginProduct, self).build(input_shape[0])\n",
        "\n",
        "        self.W = self.add_weight(\n",
        "            name='W',\n",
        "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
        "            initializer='glorot_uniform',\n",
        "            dtype='float32',\n",
        "            trainable=True,\n",
        "            regularizer=None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        X, y = inputs\n",
        "#         y = tf.cast(y, dtype=tf.int32)\n",
        "        cosine = tf.matmul(\n",
        "            tf.math.l2_normalize(X, axis=1),\n",
        "            tf.math.l2_normalize(self.W, axis=0)\n",
        "        )\n",
        "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = tf.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        one_hot = tf.cast(y, dtype=cosine.dtype)\n",
        "        if self.ls_eps > 0:\n",
        "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
        "\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        output *= self.s\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD3EEADdQEsl"
      },
      "source": [
        "def get_model():\n",
        "    margin = ArcMarginProduct(n_classes=NUMBER_OF_CLASSES, s=64, m=0.05, \n",
        "                            name='head/arc_margin', dtype='float32')\n",
        "    img_adjust_layer = tf.keras.layers.Lambda(tf.keras.applications.resnet_v2.preprocess_input, input_shape=[*IMAGE_SIZE, 3])\n",
        "    base_model = tf.keras.applications.resnet_v2.ResNet152V2(weights=None, include_top=False)\n",
        "\n",
        "    image = tf.keras.Input(shape=(*IMAGE_SIZE,3), name='inp1')\n",
        "    label = tf.keras.Input(shape=(NUMBER_OF_CLASSES,), name='inp2')\n",
        "\n",
        "    x = img_adjust_layer(image)\n",
        "    x = base_model(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(512)(x)\n",
        "    x = margin([x, label])\n",
        "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs = [image, label], outputs = [output])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "        loss=[tf.keras.losses.CategoricalCrossentropy()],  \n",
        "        metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo7cYeAmQJIB"
      },
      "source": [
        "model = get_model()\n",
        "model.load_weights('/content/drive/MyDrive/kaggle/google-landmark-recognition-2021/resnetv2/best_weights.h5')\n",
        "model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHbxkx8nQWQZ"
      },
      "source": [
        "def generate_embeddings(filepaths, model, size):\n",
        "    dataset = get_dataset(filepaths, labeled=False, ordered=False)\n",
        "    ids = np.empty((size,), dtype='<U16')\n",
        "    embeddings = np.empty((size, NUM_EMBEDDING_DIMENSIONS))\n",
        "    num_batches = math.ceil(size/BATCH_SIZE)\n",
        "\n",
        "    for i, batch in tqdm(zip(range(0, size, BATCH_SIZE),dataset), total=num_batches):\n",
        "        image, idnum = batch\n",
        "        prediction = model.predict(image) #batch_size, 512\n",
        "        ids[i:i+BATCH_SIZE] = idnum.numpy().astype('str')\n",
        "        embeddings[i:i+BATCH_SIZE] = prediction\n",
        "        del image, idnum, batch, prediction\n",
        "        gc.collect()\n",
        "\n",
        "    return ids, embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv3f971hQ4zZ"
      },
      "source": [
        "train_ids, ids = generate_embeddings(filepaths, model, size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkRSeMZ_Q0v1"
      },
      "source": [
        "with open('/content/drive/MyDrive/kaggle/google-landmark-recognition-2021/embeddings.npy', 'wb') as f:\n",
        "    np.save(f, train_ids)\n",
        "    np.save(f, ids)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}